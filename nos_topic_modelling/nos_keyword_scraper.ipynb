{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "http_proxy = \"http://92.63.168.248:80\"\n",
    "proxies = {\"http\" : http_proxy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_keywords(keyword):\n",
    "    urls = []\n",
    "    page = 1\n",
    "    \n",
    "    # Loop through the pages of the search results\n",
    "    while True:\n",
    "        url = 'https://nos.nl/zoeken?q=' + keyword + '&page=' + str(page)\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Check if there are any results\n",
    "        search = soup.find('form').find('ul')\n",
    "        if search.find('span').get_text() == \"Geen resultaten gevonden\":\n",
    "            break\n",
    "        \n",
    "        # Loop through the articles on the page\n",
    "        links = search.select('li > a')\n",
    "        for link in links:\n",
    "            title = link.find('h2').get_text().strip()\n",
    "            article_url = 'https://nos.nl' + link.get(\"href\")\n",
    "            date = link.find('time').get('datetime')\n",
    "            parsed_datetime = datetime.datetime.strptime(date, '%Y-%m-%dT%H:%M:%S%z').strftime('%Y-%m-%d')\n",
    "            new_entry = {\"title\": title, \"url\": article_url, 'date': parsed_datetime}\n",
    "\n",
    "            # Check if it is an article\n",
    "            if '/artikel/' in new_entry['url']:\n",
    "                urls.append(new_entry)\n",
    "        \n",
    "        page += 1\n",
    "\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hittestress: 44\n",
      "hittegolf: 412\n",
      "warmte golf: 12\n",
      "hitteplan: 82\n",
      "temperatuurrecords: 26\n",
      "hoge temperaturen: 598\n",
      "tropische temperaturen: 168\n",
      "warmte in Nederland: 452\n",
      "hoge temperaturen Nederland: 216\n",
      "RIVM hitte: 64\n",
      "KNMI hitte: 100\n"
     ]
    }
   ],
   "source": [
    "keywords = ['hittestress', 'hittegolf', 'warmte golf', 'hitteplan', 'temperatuurrecords', 'hoge temperaturen', 'tropische temperaturen', \n",
    "            'warmte in Nederland', 'hoge temperaturen Nederland', 'RIVM hitte', 'KNMI hitte']\n",
    "\n",
    "result = []\n",
    "for keyword in keywords:\n",
    "    r = scrape_keywords(keyword)\n",
    "    print(f\"{keyword}: {len(r)}\")\n",
    "    result += r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1448, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(result)\n",
    "data.drop_duplicates(subset=['url'], inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1448, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>scraped</th>\n",
       "      <th>tag</th>\n",
       "      <th>collections</th>\n",
       "      <th>text</th>\n",
       "      <th>subheadings</th>\n",
       "      <th>image_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zuid-Franse druiven groeien door klimaatverand...</td>\n",
       "      <td>https://nos.nl/artikel/2481980-zuid-franse-dru...</td>\n",
       "      <td>2023-07-08</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steeds meer mensen een airco, maar experts zie...</td>\n",
       "      <td>https://nos.nl/artikel/2481925-steeds-meer-men...</td>\n",
       "      <td>2023-07-07</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hofplein in Rotterdam op de schop: minder auto...</td>\n",
       "      <td>https://nos.nl/artikel/2479795-hofplein-in-rot...</td>\n",
       "      <td>2023-06-21</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Klimaatverandering kan desastreuze gezondheid...</td>\n",
       "      <td>https://nos.nl/artikel/2477696-klimaatverander...</td>\n",
       "      <td>2023-06-04</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Varkens in slachthuizen lijden onnodig, NVWA g...</td>\n",
       "      <td>https://nos.nl/nieuwsuur/artikel/2471637-varke...</td>\n",
       "      <td>2023-04-16</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Zuid-Franse druiven groeien door klimaatverand...   \n",
       "1  Steeds meer mensen een airco, maar experts zie...   \n",
       "2  Hofplein in Rotterdam op de schop: minder auto...   \n",
       "3  'Klimaatverandering kan desastreuze gezondheid...   \n",
       "4  Varkens in slachthuizen lijden onnodig, NVWA g...   \n",
       "\n",
       "                                                 url        date  scraped  \\\n",
       "0  https://nos.nl/artikel/2481980-zuid-franse-dru...  2023-07-08    False   \n",
       "1  https://nos.nl/artikel/2481925-steeds-meer-men...  2023-07-07    False   \n",
       "2  https://nos.nl/artikel/2479795-hofplein-in-rot...  2023-06-21    False   \n",
       "3  https://nos.nl/artikel/2477696-klimaatverander...  2023-06-04    False   \n",
       "4  https://nos.nl/nieuwsuur/artikel/2471637-varke...  2023-04-16    False   \n",
       "\n",
       "    tag collections  text subheadings image_urls  \n",
       "0  None        None  None        None       None  \n",
       "1  None        None  None        None       None  \n",
       "2  None        None  None        None       None  \n",
       "3  None        None  None        None       None  \n",
       "4  None        None  None        None       None  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"scraped\"] = False\n",
    "data[\"tag\"] = None\n",
    "data[\"collections\"] = None\n",
    "data[\"text\"] = None\n",
    "data[\"subheadings\"] = None\n",
    "data[\"image_urls\"] = None\n",
    "\n",
    "with open('articles.df.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1448/1448 complete.\r"
     ]
    }
   ],
   "source": [
    "with open('articles.df.pkl', 'rb') as f:\n",
    "    df_articles = pickle.load(f)\n",
    "\n",
    "classes = ['sc-703c8009-0 bNWqny', 'sc-ec7ecbea-0 ijYtkw sc-e0c07641-6 hkOGKG']\n",
    "length = len(df_articles.index)\n",
    "number = 1\n",
    "\n",
    "# run through all articles and retrieve tags, collections, subheadings, text, and image urls\n",
    "while (df_articles[\"scraped\"] == False).any():\n",
    "    # with open('articles.df.pkl', 'rb') as f:\n",
    "    #     df_articles = pickle.load(f)\n",
    "\n",
    "    df_not_scraped = df_articles[df_articles[\"scraped\"] == False]\n",
    "    url = df_not_scraped.iloc[0][\"url\"]\n",
    "    response = requests.get(url)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # remove relevant articles and share divs\n",
    "    for element in classes:\n",
    "        for div in soup.find_all(\"div\", {'class':element}):     \n",
    "            div.decompose()\n",
    "\n",
    "    # get tag text\n",
    "    try:\n",
    "        tag = soup.find(True, {'data-testid':\"pill-with-label\"}).text.strip()\n",
    "    except:\n",
    "        tag = None\n",
    "\n",
    "    # get subheadings html list\n",
    "    body_subheadings = soup.select('h2.sc-b9829a65-0.jOMHUX')\n",
    "    # get text and add each to a list\n",
    "    subheadings = []\n",
    "    for subheading in body_subheadings:\n",
    "        subheadings.append(subheading.get_text())\n",
    "\n",
    "    if len(subheadings) == 0:\n",
    "        subheadings = None\n",
    "\n",
    "    # get body html list\n",
    "    body_text  = soup.select('div.sc-e0c07641-1.eHATPt')[1:]\n",
    "    # get text and add to a string\n",
    "    string = \"\"\n",
    "    for paragraph in body_text:\n",
    "        if paragraph.find('tbody') is None:\n",
    "            paragraph = paragraph.get_text()\n",
    "            string = string + paragraph + \"\\n\"\n",
    "    text = string.strip()\n",
    "\n",
    "    # get any image urls\n",
    "    # image_url_list = soup.select('img.sc-89aee953-1.dQLfsp')\n",
    "    figure_list = soup.find_all('figure')\n",
    "    image_urls = []\n",
    "    # get text and add each to a list\n",
    "    for figure in figure_list:\n",
    "        image_url = figure.find('img')\n",
    "        image_url = image_url['src']\n",
    "        \n",
    "        image_caption = figure.find('figcaption')\n",
    "        if image_caption is not None:\n",
    "            image_caption = image_caption.get_text().strip()\n",
    "    \n",
    "        image_urls.append({\"image_url\": image_url, \"caption\": image_caption})\n",
    "    \n",
    "    if len(image_urls) == 0:\n",
    "        image_urls = None\n",
    "    \n",
    "    # get collections\n",
    "    collections_list = soup.select('div.sc-703c8009-0.sc-db08e33-0.bNWqny.dxKSik p')\n",
    "    # get collection and add each to a list\n",
    "    collections = []\n",
    "    for collection in collections_list:\n",
    "        collection = collection.get_text()\n",
    "        collections.append(collection)\n",
    "\n",
    "    if len(collections) == 0:\n",
    "        collections = None\n",
    "\n",
    "    # add items to dataframe\n",
    "    index = df_articles.index[df_articles[\"url\"] == url].tolist()\n",
    "\n",
    "    df_articles.at[index[0], \"tag\"] = tag\n",
    "    df_articles.at[index[0], \"collections\"] = collections\n",
    "    df_articles.at[index[0], \"subheadings\"] = subheadings\n",
    "    df_articles.at[index[0], \"text\"] = text\n",
    "    df_articles.at[index[0], \"image_urls\"] = image_urls\n",
    "    df_articles.at[index[0], \"scraped\"] = True\n",
    "\n",
    "    #df_articles.to_pickle('articles.df.pkl')\n",
    "\n",
    "    print(f\"{number}/{length} complete.\", end=\"\\r\")\n",
    "\n",
    "    number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles.drop(columns=['scraped'], inplace=True)\n",
    "df_articles.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>tag</th>\n",
       "      <th>collections</th>\n",
       "      <th>text</th>\n",
       "      <th>subheadings</th>\n",
       "      <th>image_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zuid-Franse druiven groeien door klimaatverand...</td>\n",
       "      <td>https://nos.nl/artikel/2481980-zuid-franse-dru...</td>\n",
       "      <td>2023-07-08</td>\n",
       "      <td>None</td>\n",
       "      <td>[Economie]</td>\n",
       "      <td>Tegen de heuvels rond Maastricht werden vijfti...</td>\n",
       "      <td>[Einde aan uienteelt]</td>\n",
       "      <td>[{'image_url': 'https://cdn.nos.nl/image/2023/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Steeds meer mensen een airco, maar experts zie...</td>\n",
       "      <td>https://nos.nl/artikel/2481925-steeds-meer-men...</td>\n",
       "      <td>2023-07-07</td>\n",
       "      <td>None</td>\n",
       "      <td>[Binnenland]</td>\n",
       "      <td>Op hete dagen zijn mobiele airco's in winkels ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'image_url': 'https://cdn.nos.nl/image/2023/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hofplein in Rotterdam op de schop: minder auto...</td>\n",
       "      <td>https://nos.nl/artikel/2479795-hofplein-in-rot...</td>\n",
       "      <td>2023-06-21</td>\n",
       "      <td>None</td>\n",
       "      <td>[In samenwerking met, Rijnmond, Regionaal nieuws]</td>\n",
       "      <td>Het Hofplein in het centrum van Rotterdam gaat...</td>\n",
       "      <td>[Kosten hoger dan verwacht]</td>\n",
       "      <td>[{'image_url': 'https://cdn.nos.nl/image/2023/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Klimaatverandering kan desastreuze gezondheid...</td>\n",
       "      <td>https://nos.nl/artikel/2477696-klimaatverander...</td>\n",
       "      <td>2023-06-04</td>\n",
       "      <td>Klimaat</td>\n",
       "      <td>[Collectie, Klimaat, Binnenland, Buitenland]</td>\n",
       "      <td>Dat klimaatverandering kan leiden tot bijvoorb...</td>\n",
       "      <td>[Directe en indirecte gevolgen, 'Toch wel een ...</td>\n",
       "      <td>[{'image_url': 'https://cdn.nos.nl/image/2023/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Varkens in slachthuizen lijden onnodig, NVWA g...</td>\n",
       "      <td>https://nos.nl/nieuwsuur/artikel/2471637-varke...</td>\n",
       "      <td>2023-04-16</td>\n",
       "      <td>None</td>\n",
       "      <td>[Nieuwsuur, Binnenland]</td>\n",
       "      <td>Vanaf volgend jaar gaat de overheid optreden t...</td>\n",
       "      <td>[Vechten, Hittestress]</td>\n",
       "      <td>[{'image_url': 'https://cdn.nos.nl/image/2023/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>KNMI: 's middags kans op zwaar onweer</td>\n",
       "      <td>https://nos.nl/artikel/2045194-knmi-s-middags-...</td>\n",
       "      <td>2015-07-04</td>\n",
       "      <td>None</td>\n",
       "      <td>[Binnenland]</td>\n",
       "      <td>Zondagmiddag komt er met zwaar onweer een eind...</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'image_url': 'https://cdn.nos.nl/image/2015/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>Utrecht klaar voor Grand Départ</td>\n",
       "      <td>https://nos.nl/artikel/2045063-utrecht-klaar-v...</td>\n",
       "      <td>2015-07-04</td>\n",
       "      <td>None</td>\n",
       "      <td>[Binnenland]</td>\n",
       "      <td>Utrecht maakt zich op voor de start van de Tou...</td>\n",
       "      <td>[Vignetten , Iets minder warm]</td>\n",
       "      <td>[{'image_url': 'https://cdn.nos.nl/image/2015/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>Code oranje beëindigd; lokaal problemen door b...</td>\n",
       "      <td>https://nos.nl/artikel/2039710-code-oranje-bee...</td>\n",
       "      <td>2015-06-05</td>\n",
       "      <td>None</td>\n",
       "      <td>[Binnenland]</td>\n",
       "      <td>Het KNMI heeft even na 21.00 uur code oranje b...</td>\n",
       "      <td>[Code oranje, België]</td>\n",
       "      <td>[{'image_url': 'https://cdn.nos.nl/image/2015/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>90-jarige weerman: dit werk houdt een mens jong</td>\n",
       "      <td>https://nos.nl/artikel/2020237-90-jarige-weerm...</td>\n",
       "      <td>2015-02-19</td>\n",
       "      <td>None</td>\n",
       "      <td>[Binnenland]</td>\n",
       "      <td>Hij heeft veel bewonderaars die graag een plan...</td>\n",
       "      <td>[Vreeslyk gehuil ]</td>\n",
       "      <td>[{'image_url': 'https://cdn.nos.nl/image/2015/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>Recreatieplassen Utrecht \"propvol\"</td>\n",
       "      <td>https://nos.nl/artikel/531826-recreatieplassen...</td>\n",
       "      <td>2013-07-21</td>\n",
       "      <td>None</td>\n",
       "      <td>[Binnenland]</td>\n",
       "      <td>De Utrechtse politie roept mensen op niet meer...</td>\n",
       "      <td>[Code geel\\n]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1448 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     Zuid-Franse druiven groeien door klimaatverand...   \n",
       "1     Steeds meer mensen een airco, maar experts zie...   \n",
       "2     Hofplein in Rotterdam op de schop: minder auto...   \n",
       "3     'Klimaatverandering kan desastreuze gezondheid...   \n",
       "4     Varkens in slachthuizen lijden onnodig, NVWA g...   \n",
       "...                                                 ...   \n",
       "1443              KNMI: 's middags kans op zwaar onweer   \n",
       "1444                    Utrecht klaar voor Grand Départ   \n",
       "1445  Code oranje beëindigd; lokaal problemen door b...   \n",
       "1446    90-jarige weerman: dit werk houdt een mens jong   \n",
       "1447                 Recreatieplassen Utrecht \"propvol\"   \n",
       "\n",
       "                                                    url        date      tag  \\\n",
       "0     https://nos.nl/artikel/2481980-zuid-franse-dru...  2023-07-08     None   \n",
       "1     https://nos.nl/artikel/2481925-steeds-meer-men...  2023-07-07     None   \n",
       "2     https://nos.nl/artikel/2479795-hofplein-in-rot...  2023-06-21     None   \n",
       "3     https://nos.nl/artikel/2477696-klimaatverander...  2023-06-04  Klimaat   \n",
       "4     https://nos.nl/nieuwsuur/artikel/2471637-varke...  2023-04-16     None   \n",
       "...                                                 ...         ...      ...   \n",
       "1443  https://nos.nl/artikel/2045194-knmi-s-middags-...  2015-07-04     None   \n",
       "1444  https://nos.nl/artikel/2045063-utrecht-klaar-v...  2015-07-04     None   \n",
       "1445  https://nos.nl/artikel/2039710-code-oranje-bee...  2015-06-05     None   \n",
       "1446  https://nos.nl/artikel/2020237-90-jarige-weerm...  2015-02-19     None   \n",
       "1447  https://nos.nl/artikel/531826-recreatieplassen...  2013-07-21     None   \n",
       "\n",
       "                                            collections  \\\n",
       "0                                            [Economie]   \n",
       "1                                          [Binnenland]   \n",
       "2     [In samenwerking met, Rijnmond, Regionaal nieuws]   \n",
       "3          [Collectie, Klimaat, Binnenland, Buitenland]   \n",
       "4                               [Nieuwsuur, Binnenland]   \n",
       "...                                                 ...   \n",
       "1443                                       [Binnenland]   \n",
       "1444                                       [Binnenland]   \n",
       "1445                                       [Binnenland]   \n",
       "1446                                       [Binnenland]   \n",
       "1447                                       [Binnenland]   \n",
       "\n",
       "                                                   text  \\\n",
       "0     Tegen de heuvels rond Maastricht werden vijfti...   \n",
       "1     Op hete dagen zijn mobiele airco's in winkels ...   \n",
       "2     Het Hofplein in het centrum van Rotterdam gaat...   \n",
       "3     Dat klimaatverandering kan leiden tot bijvoorb...   \n",
       "4     Vanaf volgend jaar gaat de overheid optreden t...   \n",
       "...                                                 ...   \n",
       "1443  Zondagmiddag komt er met zwaar onweer een eind...   \n",
       "1444  Utrecht maakt zich op voor de start van de Tou...   \n",
       "1445  Het KNMI heeft even na 21.00 uur code oranje b...   \n",
       "1446  Hij heeft veel bewonderaars die graag een plan...   \n",
       "1447  De Utrechtse politie roept mensen op niet meer...   \n",
       "\n",
       "                                            subheadings  \\\n",
       "0                                 [Einde aan uienteelt]   \n",
       "1                                                  None   \n",
       "2                           [Kosten hoger dan verwacht]   \n",
       "3     [Directe en indirecte gevolgen, 'Toch wel een ...   \n",
       "4                                [Vechten, Hittestress]   \n",
       "...                                                 ...   \n",
       "1443                                               None   \n",
       "1444                     [Vignetten , Iets minder warm]   \n",
       "1445                              [Code oranje, België]   \n",
       "1446                                 [Vreeslyk gehuil ]   \n",
       "1447                                      [Code geel\\n]   \n",
       "\n",
       "                                             image_urls  \n",
       "0     [{'image_url': 'https://cdn.nos.nl/image/2023/...  \n",
       "1     [{'image_url': 'https://cdn.nos.nl/image/2023/...  \n",
       "2     [{'image_url': 'https://cdn.nos.nl/image/2023/...  \n",
       "3     [{'image_url': 'https://cdn.nos.nl/image/2023/...  \n",
       "4     [{'image_url': 'https://cdn.nos.nl/image/2023/...  \n",
       "...                                                 ...  \n",
       "1443  [{'image_url': 'https://cdn.nos.nl/image/2015/...  \n",
       "1444  [{'image_url': 'https://cdn.nos.nl/image/2015/...  \n",
       "1445  [{'image_url': 'https://cdn.nos.nl/image/2015/...  \n",
       "1446  [{'image_url': 'https://cdn.nos.nl/image/2015/...  \n",
       "1447                                               None  \n",
       "\n",
       "[1448 rows x 8 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles.to_csv(\"nos_keywords2.csv\")\n",
    "df_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
